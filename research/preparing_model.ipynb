{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\teck1\\\\OneDrive\\\\Documents\\\\GitHub\\\\ai'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    params_image_size: list\n",
    "    params_learning_rate: float\n",
    "    params_include_top: bool\n",
    "    params_weights: str\n",
    "    params_classes: int\n",
    "    params_image_height: int\n",
    "    params_image_width: int\n",
    "    params_sequence: int\n",
    "    params_classes_list: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DetectAnalytics.constants import *\n",
    "from DetectAnalytics.utils.common import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath = CONFIG_FILE_PATH,\n",
    "            params_filepath = PARAMS_FILE_PATH):\n",
    "            self.config = read_yaml(config_filepath)\n",
    "            self.params = read_yaml(params_filepath)\n",
    "            create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_prepare_base_model_config(self) -> PrepareModelConfig:\n",
    "        config = self.config.preparing_model\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prepare_model_config = PrepareModelConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            base_model_path=Path(config.base_model_path),\n",
    "            updated_base_model_path=Path(config.updated_base_model_path),\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_learning_rate=self.params.LEARNING_RATE,\n",
    "            params_include_top=self.params.INCLUDE_TOP,\n",
    "            params_weights=self.params.WEIGHTS,\n",
    "            params_classes=self.params.CLASSES,\n",
    "            params_image_height=self.params.IMAGE_HEIGHT,\n",
    "            params_image_width=self.params.IMAGE_WIDTH,\n",
    "            params_sequence=self.params.SEQUENCE,\n",
    "            params_classes_list=self.params.CLASSES_LIST\n",
    "        )\n",
    "\n",
    "        return prepare_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import datetime as dt\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareBaseModel:\n",
    "    def __init__(self, config: PrepareModelConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    \n",
    "    def get_base_model(self):\n",
    "\n",
    "        self.model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "            include_top=self.config.params_include_top,\n",
    "            weights=self.config.params_weights\n",
    "        )\n",
    "\n",
    "        self.model.trainable = True\n",
    "        for layer in self.model.layers[:-40]:\n",
    "            layer.trainable=False\n",
    "            \n",
    "        self.save_model(path=self.config.base_model_path, model=self.model)\n",
    "\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _prepare_full_model(model, classes, freeze_all, freeze_till, learning_rate, image_size):\n",
    "\n",
    "        sequential = tf.keras.models.Sequential()\n",
    "        sequential.add(tf.keras.layers.Input(shape = (image_size)))\n",
    "        sequential.add(tf.keras.layers.TimeDistributed(model))\n",
    "        sequential.add(tf.keras.layers.Dropout(0.25))\n",
    "        sequential.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))\n",
    "        lstm_fw = tf.keras.layers.LSTM(units=32)\n",
    "        lstm_bw = tf.keras.layers.LSTM(units=32, go_backwards=True)\n",
    "        sequential.add(tf.keras.layers.Bidirectional(lstm_fw, backward_layer = lstm_bw))\n",
    "        sequential.add(tf.keras.layers.Dropout(0.25))\n",
    "        sequential.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "        sequential.add(tf.keras.layers.Dropout(0.25))\n",
    "        sequential.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        sequential.add(tf.keras.layers.Dropout(0.25))\n",
    "        sequential.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "        sequential.add(tf.keras.layers.Dropout(0.25))\n",
    "        sequential.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "        sequential.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "        sequential.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
    "\n",
    "        sequential.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        sequential.summary()\n",
    "        return sequential\n",
    "    \n",
    "\n",
    "    def update_base_model(self):\n",
    "        self.full_model = self._prepare_full_model(\n",
    "            model=self.model,\n",
    "            classes=self.config.params_classes,\n",
    "            freeze_all=True,\n",
    "            freeze_till=None,\n",
    "            learning_rate=self.config.params_learning_rate,\n",
    "            image_size=self.config.params_image_size\n",
    "        )\n",
    "\n",
    "        self.save_model(path=self.config.updated_base_model_path, model=self.full_model)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-17 20:10:13,393: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-12-17 20:10:13,396: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-17 20:10:13,401: INFO: common: created directory at: artifacts]\n",
      "[2023-12-17 20:10:13,401: INFO: common: created directory at: artifacts/preparing_model]\n",
      "[2023-12-17 20:10:13,402: WARNING: mobilenet_v2: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.]\n",
      "[2023-12-17 20:10:14,308: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teck1\\miniconda3\\envs\\detectai\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_10 (TimeD  (None, 16, 2, 2, 1280)    2257984   \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 16, 2, 2, 1280)    0         \n",
      "                                                                 \n",
      " time_distributed_11 (TimeD  (None, 16, 5120)          0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirecti  (None, 64)                1319168   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3637090 (13.87 MB)\n",
      "Trainable params: 3060642 (11.68 MB)\n",
      "Non-trainable params: 576448 (2.20 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_base_model_config = config.get_prepare_base_model_config()\n",
    "    prepare_base_model = PrepareBaseModel(config=prepare_base_model_config)\n",
    "    prepare_base_model.get_base_model()\n",
    "    prepare_base_model.update_base_model()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
